感觉学完，就忘记了
1.webdriver 模仿浏览器 客户行为 增加 对应浏览器python驱动
2.反反爬虫的简单验证码，灰化，二倍化，然后pytessract('chm+eng')读取文字并输入
3.还有动态点击选择图片没有讲
4.还有使用mysql数据库(mongodb没说)，pip install pymysql
5.fake_useragent import UserAgent 模拟浏览器的头部信息 cookies/referer(在那里跳转)
6.使用UserAgent 模拟登录，保存cookies
7.还有了解scrapy框架的下载中间件与自定义中间件downloaderware